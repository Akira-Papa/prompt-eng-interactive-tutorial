{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# 第1章: 基本的なプロンプト構造\n\n- [レッスン](#lesson)\n- [演習](#exercises)\n- [サンプル実験場](#example-playground)\n\n## セットアップ\n\n以下のセットアップセルを実行して、APIキーを読み込み、`get_completion`ヘルパー関数を確立してください。",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install anthropic --quiet\n",
    "\n",
    "# Import the hints module from the utils package\n",
    "import os\n",
    "import sys\n",
    "module_path = \"..\"\n",
    "sys.path.append(os.path.abspath(module_path))\n",
    "from utils import hints\n",
    "\n",
    "# Import python's built-in regular expression library\n",
    "import re\n",
    "from anthropic import AnthropicBedrock\n",
    "\n",
    "%store -r MODEL_NAME\n",
    "%store -r AWS_REGION\n",
    "\n",
    "client = AnthropicBedrock(aws_region=AWS_REGION)\n",
    "\n",
    "def get_completion(prompt, system=''):\n",
    "    message = client.messages.create(\n",
    "        model=MODEL_NAME,\n",
    "        max_tokens=2000,\n",
    "        temperature=0.0,\n",
    "        messages=[\n",
    "          {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        system=system\n",
    "    )\n",
    "    return message.content[0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## レッスン\n\nAnthropicはレガシーAPI（旧版）である[Text Completions API](https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters-anthropic-claude-text-completion.html)と現在の[Messages API](https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters-anthropic-claude-messages.html)の2つのAPIを提供しています。このチュートリアルでは、Messages APIのみを使用します。\n\nMessages APIを使用してClaudeを呼び出すには、最低限以下のパラメータが必要です：\n- `model`: 呼び出すモデルの[APIモデル名](https://docs.aws.amazon.com/bedrock/latest/userguide/model-ids.html#model-ids-arns)\n\n- `max_tokens`: 停止する前に生成するトークンの最大数。Claudeはこの最大値に達する前に停止する場合があることに注意してください。このパラメータは生成するトークンの絶対最大数のみを指定します。さらに、これは*ハード*ストップであり、Claudeが単語や文の途中で生成を停止する可能性があります。\n\n- `messages`: 入力メッセージの配列。私たちのモデルは、`user`（ユーザー）と`assistant`（アシスタント）の会話ターンが交互に行われるように訓練されています。新しい`Message`を作成する際、messagesパラメータで以前の会話ターンを指定すると、モデルは会話の次の`Message`を生成します。\n  - 各入力メッセージは`role`と`content`を持つオブジェクトである必要があります。単一の`user`ロールメッセージを指定することも、複数の`user`と`assistant`メッセージを含めることもできます（その場合は交互である必要があります）。最初のメッセージは常に`user`ロールを使用する必要があります。\n\n以下のようなオプションパラメータもあります：\n- `system`: システムプロンプト - 詳細は以下で説明します。\n  \n- `temperature`: Claudeの応答の変動度。これらのレッスンと演習では、`temperature`を0に設定しています。\n\nすべてのAPIパラメータの完全なリストについては、[APIドキュメント](https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters-claude.html)をご覧ください。",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### 例\n\n正しくフォーマットされたプロンプトに対してClaudeがどのように応答するかを見てみましょう。以下の各セルについて、セルを実行（`shift+enter`）すると、Claudeの応答がブロックの下に表示されます。",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt\n",
    "PROMPT = \"Hi Claude, how are you?\"\n",
    "\n",
    "# Print Claude's response\n",
    "print(get_completion(PROMPT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt\n",
    "PROMPT = \"Can you tell me the color of the ocean?\"\n",
    "\n",
    "# Print Claude's response\n",
    "print(get_completion(PROMPT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt\n",
    "PROMPT = \"What year was Celine Dion born in?\"\n",
    "\n",
    "# Print Claude's response\n",
    "print(get_completion(PROMPT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "次に、正しいMessages APIフォーマットが含まれていないプロンプトを見てみましょう。これらの誤ったフォーマットのプロンプトに対して、Messages APIはエラーを返します。\n\nまず、`messages`配列に`role`と`content`フィールドが欠けているMessages API呼び出しの例を示します。",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "> ⚠️ **警告：** プロンプトのmessagesパラメータの書式が正しくないため、以下のセルはエラーを返します。これは期待される動作です。",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Claude's response\n",
    "response = client.messages.create(\n",
    "        model=MODEL_NAME,\n",
    "        max_tokens=2000,\n",
    "        temperature=0.0,\n",
    "        messages=[\n",
    "          {\"Hi Claude, how are you?\"}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "# Print Claude's response\n",
    "print(response[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "以下は、`user`と`assistant`ロールが交互になっていないプロンプトです。",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "> ⚠️ **警告：** `user`と`assistant`ロールが交互になっていないため、Claudeはエラーメッセージを返します。これは期待される動作です。",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Claude's response\n",
    "response = client.messages.create(\n",
    "        model=MODEL_NAME,\n",
    "        max_tokens=2000,\n",
    "        temperature=0.0,\n",
    "        messages=[\n",
    "          {\"role\": \"user\", \"content\": \"What year was Celine Dion born in?\"},\n",
    "          {\"role\": \"user\", \"content\": \"Also, can you tell me some other facts about her?\"}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "# Print Claude's response\n",
    "print(response[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "`user`と`assistant`メッセージは**必ず交互に**配置し、メッセージは**必ず`user`ターンで開始する**必要があります。プロンプト内に複数の`user`と`assistant`のペアを含めることもできます（マルチターン会話をシミュレートするかのように）。また、終端の`assistant`メッセージに単語を配置して、Claudeがあなたが中断したところから続きを生成するようにすることもできます（詳細は後の章で説明します）。\n\n#### システムプロンプト\n\n**システムプロンプト**も使用できます。システムプロンプトは、「User」ターンで質問やタスクを提示する前に、**Claudeにコンテキスト、指示、ガイドラインを提供**する方法です。\n\n構造的には、システムプロンプトは`user`と`assistant`メッセージのリストとは別に存在し、そのため別の`system`パラメータに属します（ノートブックの[セットアップ](#setup)セクションにある`get_completion`ヘルパー関数の構造を参照してください）。\n\nこのチュートリアル内でシステムプロンプトを利用する場合は、completion関数に`system`フィールドを用意しています。システムプロンプトを使用したくない場合は、単に`SYSTEM_PROMPT`変数を空の文字列に設定してください。",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "#### システムプロンプトの例",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System prompt\n",
    "SYSTEM_PROMPT = \"Your answer should always be a series of critical thinking questions that further the conversation (do not provide answers to your questions). Do not actually answer the user question.\"\n",
    "\n",
    "# Prompt\n",
    "PROMPT = \"Why is the sky blue?\"\n",
    "\n",
    "# Print Claude's response\n",
    "print(get_completion(PROMPT, SYSTEM_PROMPT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "なぜシステムプロンプトを使用するのでしょうか？**適切に書かれたシステムプロンプトは、様々な方法でClaudeのパフォーマンスを向上させることができます**。例えば、ルールや指示に従うClaudeの能力を向上させることができます。詳細については、Claudeでの[システムプロンプトの使用方法](https://docs.anthropic.com/claude/docs/how-to-use-system-prompts)に関するドキュメントをご覧ください。\n\n次は演習に進みます。上記の内容を変更せずにレッスンのプロンプトを試したい場合は、レッスンノートブックの最下部にある[**サンプル実験場**](#example-playground)にスクロールしてください。",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## 演習\n- [演習 1.1 - 3まで数える](#exercise-11---counting-to-three)\n- [演習 1.2 - システムプロンプト](#exercise-12---system-prompt)",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### 演習 1.1 - 3まで数える\n適切な`user` / `assistant`フォーマットを使用して、以下の`PROMPT`を編集してClaudeに**3まで数える**ように指示してください。出力では、あなたの解答が正しいかどうかも示されます。",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt - this is the only field you should change\n",
    "PROMPT = \"[Replace this text]\"\n",
    "\n",
    "# Get Claude's response\n",
    "response = get_completion(PROMPT)\n",
    "\n",
    "# Function to grade exercise correctness\n",
    "def grade_exercise(text):\n",
    "    pattern = re.compile(r'^(?=.*1)(?=.*2)(?=.*3).*$', re.DOTALL)\n",
    "    return bool(pattern.match(text))\n",
    "\n",
    "# Print Claude's response and the corresponding grade\n",
    "print(response)\n",
    "print(\"\\n--------------------------- GRADING ---------------------------\")\n",
    "print(\"This exercise has been correctly solved:\", grade_exercise(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "❓ ヒントが必要な場合は、以下のセルを実行してください！",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hints.exercise_1_1_hint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### 演習 1.2 - システムプロンプト\n\n`SYSTEM_PROMPT`を修正して、Claudeが3歳の子どものように応答するようにしてください。",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System prompt - this is the only field you should change\n",
    "SYSTEM_PROMPT = \"[Replace this text]\"\n",
    "\n",
    "# Prompt\n",
    "PROMPT = \"How big is the sky?\"\n",
    "\n",
    "# Get Claude's response\n",
    "response = get_completion(PROMPT, SYSTEM_PROMPT)\n",
    "\n",
    "# Function to grade exercise correctness\n",
    "def grade_exercise(text):\n",
    "    return bool(re.search(r\"giggles\", text) or re.search(r\"soo\", text))\n",
    "\n",
    "# Print Claude's response and the corresponding grade\n",
    "print(response)\n",
    "print(\"\\n--------------------------- GRADING ---------------------------\")\n",
    "print(\"This exercise has been correctly solved:\", grade_exercise(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "❓ ヒントが必要な場合は、以下のセルを実行してください！",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hints.exercise_1_2_hint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### おめでとうございます！\n\nこの時点ですべての演習を解けていれば、次の章に進む準備ができています。プロンプト作成を楽しんでください！",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## サンプル実験場\n\nこれは、このレッスンで示されたプロンプトサンプルを自由に試し、プロンプトを調整してClaudeの応答にどのような影響があるかを確認するためのエリアです。",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt\n",
    "PROMPT = \"Hi Claude, how are you?\"\n",
    "\n",
    "# Print Claude's response\n",
    "print(get_completion(PROMPT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt\n",
    "PROMPT = \"Can you tell me the color of the ocean?\"\n",
    "\n",
    "# Print Claude's response\n",
    "print(get_completion(PROMPT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt\n",
    "PROMPT = \"What year was Celine Dion born in?\"\n",
    "\n",
    "# Print Claude's response\n",
    "print(get_completion(PROMPT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Claude's response\n",
    "response = client.messages.create(\n",
    "        model=MODEL_NAME,\n",
    "        max_tokens=2000,\n",
    "        temperature=0.0,\n",
    "        messages=[\n",
    "          {\"Hi Claude, how are you?\"}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "# Print Claude's response\n",
    "print(response[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Claude's response\n",
    "response = client.messages.create(\n",
    "        model=MODEL_NAME,\n",
    "        max_tokens=2000,\n",
    "        temperature=0.0,\n",
    "        messages=[\n",
    "          {\"role\": \"user\", \"content\": \"What year was Celine Dion born in?\"},\n",
    "          {\"role\": \"user\", \"content\": \"Also, can you tell me some other facts about her?\"}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "# Print Claude's response\n",
    "print(response[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System prompt\n",
    "SYSTEM_PROMPT = \"Your answer should always be a series of critical thinking questions that further the conversation (do not provide answers to your questions). Do not actually answer the user question.\"\n",
    "\n",
    "# Prompt\n",
    "PROMPT = \"Why is the sky blue?\"\n",
    "\n",
    "# Print Claude's response\n",
    "print(get_completion(PROMPT, SYSTEM_PROMPT))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}