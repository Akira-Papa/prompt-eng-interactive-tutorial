{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# 第1章: 基本的なプロンプト構造\n\n- [レッスン](#lesson)\n- [演習](#exercises)\n- [サンプル実験場](#example-playground)\n\n## セットアップ\n\n以下のセットアップセルを実行して、APIキーを読み込み、`get_completion`ヘルパー関数を確立してください。",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import python's built-in regular expression library\n",
    "import re\n",
    "import boto3\n",
    "import json\n",
    "\n",
    "# Import the hints module from the utils package\n",
    "import os\n",
    "import sys\n",
    "module_path = \"..\"\n",
    "sys.path.append(os.path.abspath(module_path))\n",
    "from utils import hints\n",
    "\n",
    "# Retrieve the MODEL_NAME variable from the IPython store\n",
    "%store -r MODEL_NAME\n",
    "%store -r AWS_REGION\n",
    "\n",
    "client = boto3.client('bedrock-runtime',region_name=AWS_REGION)\n",
    "\n",
    "def get_completion(prompt,system=''):\n",
    "    body = json.dumps(\n",
    "        {\n",
    "            \"anthropic_version\": '',\n",
    "            \"max_tokens\": 2000,\n",
    "            \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "            \"temperature\": 0.0,\n",
    "            \"top_p\": 1,\n",
    "            \"system\": system\n",
    "        }\n",
    "    )\n",
    "    response = client.invoke_model(body=body, modelId=MODEL_NAME)\n",
    "    response_body = json.loads(response.get('body').read())\n",
    "\n",
    "    return response_body.get('content')[0].get('text')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## レッスン\n\nAnthropicでは、従来の[Text Completions API](https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters-anthropic-claude-text-completion.html)と現在の[Messages API](https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters-anthropic-claude-messages.html)の2つのAPIを提供しています。このチュートリアルでは、Messages APIのみを使用します。\n\nMessages APIを使用してClaudeを呼び出すために最低限必要なパラメータは以下の通りです：\n- `model`: 呼び出し予定のモデルの[APIモデル名](https://docs.aws.amazon.com/bedrock/latest/userguide/model-ids.html#model-ids-arns)\n\n- `max_tokens`: 停止するまでに生成するトークンの最大数。Claudeはこの最大値に到達する前に停止する場合があります。このパラメータは生成するトークンの絶対最大数のみを指定します。さらに、これは*ハード*停止であり、Claudeが単語や文の途中で生成を停止する場合があります。\n\n- `messages`: 入力メッセージの配列。私たちのモデルは、`user`と`assistant`の会話ターンが交互に行われるように訓練されています。新しい`Message`を作成する際は、messagesパラメータで過去の会話ターンを指定し、モデルが会話の次の`Message`を生成します。\n  - 各入力メッセージは`role`と`content`を持つオブジェクトである必要があります。単一の`user`ロールメッセージを指定することも、複数の`user`と`assistant`メッセージを含めることもできます（その場合は交互に配置する必要があります）。最初のメッセージは常にuserロールを使用する必要があります。\n\nまた、以下のようなオプションパラメータもあります：\n- `system`: システムプロンプト - 詳細は以下で説明します。\n  \n- `temperature`: Claudeの回答の変動性の度合い。これらのレッスンと演習では、`temperature`を0に設定しています。\n\n全APIパラメータの完全なリストについては、[APIドキュメント](https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters-claude.html)をご覧ください。",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### 例\n\n正しくフォーマットされたプロンプトに対してClaudeがどのように応答するかを見てみましょう。以下の各セルで、セルを実行し（`shift+enter`）、Claudeの回答がブロックの下に表示されます。",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt\n",
    "PROMPT = \"Hi Claude, how are you?\"\n",
    "\n",
    "# Print Claude's response\n",
    "print(get_completion(PROMPT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt\n",
    "PROMPT = \"Can you tell me the color of the ocean?\"\n",
    "\n",
    "# Print Claude's response\n",
    "print(get_completion(PROMPT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt\n",
    "PROMPT = \"What year was Celine Dion born in?\"\n",
    "\n",
    "# Print Claude's response\n",
    "print(get_completion(PROMPT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "では今度は、正しいMessages APIフォーマットが含まれていないプロンプトを見てみましょう。これらの不正な形式のプロンプトに対して、Messages APIはエラーを返します。\n\nまず、`messages`配列に`role`と`content`フィールドが不足しているMessages API呼び出しの例です。",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "> ⚠️ **警告:** プロンプトのmessagesパラメータの不正な形式により、以下のセルはエラーを返します。これは想定される動作です。",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Claude's response\n",
    "body = json.dumps(\n",
    "    {\n",
    "        \"anthropic_version\": '',\n",
    "        \"max_tokens\": 2000,\n",
    "        \"messages\": [{\"Hi Claude, how are you?\"}],\n",
    "        \"temperature\": 0.0,\n",
    "        \"top_p\": 1,\n",
    "        \"system\": ''\n",
    "    }\n",
    ")\n",
    "\n",
    "response = client.invoke_model(body=body, modelId=MODEL_NAME)\n",
    "\n",
    "# Print Claude's response\n",
    "print(response[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "こちらは`user`と`assistant`ロール間の交互配置ができていないプロンプトです。",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "> ⚠️ **警告:** `user`と`assistant`ロールの交互配置の欠如により、Claudeはエラーメッセージを返します。これは想定される動作です。",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Claude's response\n",
    "body = json.dumps(\n",
    "    {\n",
    "        \"anthropic_version\": '',\n",
    "        \"max_tokens\": 2000,\n",
    "        \"messages\": [\n",
    "          {\"role\": \"user\", \"content\": \"What year was Celine Dion born in?\"},\n",
    "          {\"role\": \"user\", \"content\": \"Also, can you tell me some other facts about her?\"}\n",
    "        ],\n",
    "        \"temperature\": 0.0,\n",
    "        \"top_p\": 1,\n",
    "        \"system\": ''\n",
    "    }\n",
    ")\n",
    "\n",
    "response = client.invoke_model(body=body, modelId=MODEL_NAME)\n",
    "\n",
    "# Print Claude's response\n",
    "print(response[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "`user`と`assistant`メッセージは**必ず交互に配置する必要があり**、メッセージは**必ず`user`ターンで開始する必要があります**。プロンプトに複数の`user`と`assistant`ペアを含めることも可能です（まるで複数ターンの会話をシミュレートするように）。また、Claudeが中断したところから続けるように、最後の`assistant`メッセージに単語を入力することも可能です（これについては後の章で詳しく説明します）。\n\n#### システムプロンプト\n\n**システムプロンプト**も使用できます。システムプロンプトは、「User」ターンで質問やタスクを提示する前に、**Claudeにコンテキスト、指示、ガイドラインを提供する**方法です。\n\n構造的には、システムプロンプトは`user`と`assistant`メッセージのリストとは別に存在し、したがって別の`system`パラメータに属します（notebookの[セットアップ](#setup)セクションの`get_completion`ヘルパー関数の構造をご覧ください）。\n\nこのチュートリアル内で、システムプロンプトを使用する可能性のある箇所では、完了関数に`system`フィールドを提供しています。システムプロンプトを使用したくない場合は、単に`SYSTEM_PROMPT`変数を空の文字列に設定してください。",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "#### システムプロンプトの例",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System prompt\n",
    "SYSTEM_PROMPT = \"Your answer should always be a series of critical thinking questions that further the conversation (do not provide answers to your questions). Do not actually answer the user question.\"\n",
    "\n",
    "# Prompt\n",
    "PROMPT = \"Why is the sky blue?\"\n",
    "\n",
    "# Print Claude's response\n",
    "print(get_completion(PROMPT, SYSTEM_PROMPT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "なぜシステムプロンプトを使用するのでしょうか？ **適切に書かれたシステムプロンプトは、Claudeのパフォーマンスを様々な方法で向上させることができます**。例えば、ルールや指示に従うClaudeの能力を向上させることができます。詳細については、Claudeで[システムプロンプトを使用する方法](https://docs.anthropic.com/claude/docs/how-to-use-system-prompts)に関するドキュメントをご覧ください。\n\n次に演習に進みます。上記の内容を変更せずにレッスンプロンプトを試したい場合は、レッスンnotebookの一番下までスクロールして[**サンプル実験場**](#example-playground)をご覧ください。",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## 演習\n- [演習 1.1 - 3まで数える](#exercise-11---counting-to-three)\n- [演習 1.2 - システムプロンプト](#exercise-12---system-prompt)",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### 演習 1.1 - 3まで数える\n適切な`user` / `assistant`形式を使用して、以下の`PROMPT`を編集してClaudeに**3まで数えさせてください。** 出力では、あなたの解答が正しいかどうかも表示されます。",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt - this is the only field you should change\n",
    "PROMPT = \"[Replace this text]\"\n",
    "\n",
    "# Get Claude's response\n",
    "response = get_completion(PROMPT)\n",
    "\n",
    "# Function to grade exercise correctness\n",
    "def grade_exercise(text):\n",
    "    pattern = re.compile(r'^(?=.*1)(?=.*2)(?=.*3).*$', re.DOTALL)\n",
    "    return bool(pattern.match(text))\n",
    "\n",
    "# Print Claude's response and the corresponding grade\n",
    "print(response)\n",
    "print(\"\\n--------------------------- GRADING ---------------------------\")\n",
    "print(\"This exercise has been correctly solved:\", grade_exercise(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "❓ ヒントが欲しい場合は、以下のセルを実行してください！",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hints.exercise_1_1_hint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### 演習 1.2 - システムプロンプト\n\n`SYSTEM_PROMPT`を修正して、Claudeが3歳の子供のように応答するようにしてください。",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System prompt - this is the only field you should change\n",
    "SYSTEM_PROMPT = \"[Replace this text]\"\n",
    "\n",
    "# Prompt\n",
    "PROMPT = \"How big is the sky?\"\n",
    "\n",
    "# Get Claude's response\n",
    "response = get_completion(PROMPT, SYSTEM_PROMPT)\n",
    "\n",
    "# Function to grade exercise correctness\n",
    "def grade_exercise(text):\n",
    "    return bool(re.search(r\"giggles\", text) or re.search(r\"soo\", text))\n",
    "\n",
    "# Print Claude's response and the corresponding grade\n",
    "print(response)\n",
    "print(\"\\n--------------------------- GRADING ---------------------------\")\n",
    "print(\"This exercise has been correctly solved:\", grade_exercise(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "❓ ヒントが欲しい場合は、以下のセルを実行してください！",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hints.exercise_1_2_hint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### おめでとうございます！\n\nここまでのすべての演習を解くことができたら、次の章に進む準備ができています。楽しいプロンプト作成を！",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## サンプル実験場\n\nここは、このレッスンで示されたプロンプトの例を自由に実験し、プロンプトを調整してClaudeの応答にどのような影響があるかを確認する場所です。",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt\n",
    "PROMPT = \"Hi Claude, how are you?\"\n",
    "\n",
    "# Print Claude's response\n",
    "print(get_completion(PROMPT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt\n",
    "PROMPT = \"Can you tell me the color of the ocean?\"\n",
    "\n",
    "# Print Claude's response\n",
    "print(get_completion(PROMPT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt\n",
    "PROMPT = \"What year was Celine Dion born in?\"\n",
    "\n",
    "# Print Claude's response\n",
    "print(get_completion(PROMPT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Claude's response\n",
    "body = json.dumps(\n",
    "    {\n",
    "        \"anthropic_version\": '',\n",
    "        \"max_tokens\": 2000,\n",
    "        \"messages\": [{\"Hi Claude, how are you?\"}],\n",
    "        \"temperature\": 0.0,\n",
    "        \"top_p\": 1,\n",
    "        \"system\": ''\n",
    "    }\n",
    ")\n",
    "\n",
    "response = client.invoke_model(body=body, modelId=MODEL_NAME)\n",
    "\n",
    "# Print Claude's response\n",
    "print(response[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Claude's response\n",
    "body = json.dumps(\n",
    "    {\n",
    "        \"anthropic_version\": '',\n",
    "        \"max_tokens\": 2000,\n",
    "        \"messages\": [\n",
    "          {\"role\": \"user\", \"content\": \"What year was Celine Dion born in?\"},\n",
    "          {\"role\": \"user\", \"content\": \"Also, can you tell me some other facts about her?\"}\n",
    "        ],\n",
    "        \"temperature\": 0.0,\n",
    "        \"top_p\": 1,\n",
    "        \"system\": ''\n",
    "    }\n",
    ")\n",
    "\n",
    "response = client.invoke_model(body=body, modelId=MODEL_NAME)\n",
    "\n",
    "# Print Claude's response\n",
    "print(response[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System prompt\n",
    "SYSTEM_PROMPT = \"Your answer should always be a series of critical thinking questions that further the conversation (do not provide answers to your questions). Do not actually answer the user question.\"\n",
    "\n",
    "# Prompt\n",
    "PROMPT = \"Why is the sky blue?\"\n",
    "\n",
    "# Print Claude's response\n",
    "print(get_completion(PROMPT, SYSTEM_PROMPT))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}